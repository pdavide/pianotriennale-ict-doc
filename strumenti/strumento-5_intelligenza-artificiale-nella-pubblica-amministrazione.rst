Strumento 5 - Intelligenza Artificiale nella Pubblica Amministrazione
=====================================================================

*Versione 1.0 del 21/12/2023*

5.1 - Anagrafica
----------------

**Ente:** AGID, Consorzio Interuniversitario Nazionale per l'Informatica
(CINI), INAIL, ISTAT, INPS

**Ufficio proponente:** -

**Destinatari:** Pubbliche amministrazioni ed enti strumentali che
erogano servizi digitali per conto delle pubbliche amministrazioni

**Capitolo del PT 2024-2026:** Capitolo 5 - Dati e intelligenza
artificiale

**Tematica:** Intelligenza artificiale

5.2 - Scenario
--------------

Un'adozione efficace e conforme alla normativa di strumenti di
Intelligenza Artificiale (IA o *AI - Artificial Intelligence,*
indifferentemente) all'interno della Pubblica Amministrazione richiede
un'attenta navigazione nel panorama legislativo corrente e una
previsione strategica delle evoluzioni future in questo ambito.

Il contesto normativo attuale mostra un crescente interesse e una serie
di iniziative di regolamentazione dell'AI ancora in divenire. Con
l'avvento di tecnologie sempre più avanzate, si rende necessario un
quadro normativo che ne guidi l'uso responsabile ed etico.

Normative come l'*AI Act*, e il GDPR (*General Data Protection
Regulation*), rappresentano elementi imprescindibili in questo percorso,
ponendo delle basi per la gestione dei dati e l'uso delle tecnologie
*AI*.

Strategicamente, l'adozione dell'*AI* nella PA deve essere allineata
con gli obiettivi a lungo termine dell'Amministrazione digitale, che
includono la digitalizzazione dei servizi, l'aumento dell'efficienza
amministrativa e la promozione di una *governance* trasparente e
accessibile. L'*AI* può giocare un ruolo cruciale in queste aree,
migliorando la capacità di analisi dei dati, automatizzando processi e
offrendo nuovi servizi ai cittadini. Per raggiungere questi risultati,
la PA deve garantire che i sistemi di Intelligenza artificiale adottati
siano affidabili, controllati da apposite procedure di gestione del
rischio, privi di implicazioni etiche e sociali negative.

5.3 - Presentazione
-------------------

Nel giugno 2023 è stato emendato il cosiddetto *AI Act*, che intende
stabilire obblighi per fornitori e utenti per mitigare i rischi legati
all'utilizzo dell'Intelligenza artificiale. Secondo l'*AI Act* i
sistemi di Intelligenza artificiale a rischio limitato dovrebbero
soddisfare requisiti minimi di trasparenza che consentano agli utenti di
prendere decisioni informate. Dopo aver interagito con le applicazioni,
l'utente può decidere se continuare a utilizzarle. In generale, gli
utenti devono essere informati quando interagiscono con l'IA. Ciò
include i sistemi di IA che generano o manipolano contenuti di immagini,
audio o video.

Nel corso dell'iter di definizione del regolamento sono stati anche
introdotti alcuni requisiti minimi di trasparenza per l'IA generativa,
che dovrebbero:

-  rivelare che il contenuto è stato generato dall'IA;

-  progettare il modello per evitare che generi contenuti illegali;

-  pubblicare riepiloghi dei dati protetti da diritto di autore e
   utilizzati per l'addestramento.

L'approfondimento del tema dell'approccio basato sul rischio dell'AI ACT
è seguito da quattro contributi di casi concreti di pubbliche
amministrazioni, che stanno realizzando applicazioni basate
sull'intelligenza artificiale.

La visione del **Laboratorio Artificial Intelligence and Intelligent
Systems** (AIIS) del CINI parte dalla considerazione che, tenendo conto
delle incertezze e della rapida evoluzione del contesto, nel breve
periodo occorre partire da una fase di acquisizione sistematica di
conoscenze, che poi dovrà essere seguita negli anni successivi da un
approccio operativo. In questa ottica, vengono individuati tre obiettivi
principali:

-  Acquisizione di conoscenze e strumenti per l'analisi del rischio
   nell'adozione di strumenti di AI

-  Acquisizione di conoscenze sui principali standard Internazionali
   applicabili a prodotti e servizi basati su AI

-  Analisi e gestione dei dati da utilizzare in applicazioni basate su
   AI

Vengono forniti suggerimenti per le azioni dirette alle PA

-  Predisposizione di strumenti per l'analisi del rischio

-  Sviluppo di metodologie e procedure di valutazione per applicazioni
   AI

-  Assicurare Linee guida sulla raccolta e il trattamento di dati
   finalizzati all'utilizzo in sistemi AI

-  Progettazione e adozione di un piano di competenze per l'AI

-  Progettazione e adozione di un piano dei fabbisogni

Il contributo dell'**INAIL** analizza le sfide, le opportunità e i
benefici derivanti dai progetti di IA dell'INAIL, quali siano le
prospettive future in questo ambito e i progetti attualmente in corso.
Nel contesto dell'organizzazione e dei processi, INAIL si è dotata di un
modello maturo di *Open Innovation* per gestire le innovazioni e i
cambiamenti che avverranno nei prossimi mesi, anche dal punto di vista
legislativo. L'introduzione dell'*AI Act*, infatti, comporterà
adeguamenti normativi per l'INAIL sia come fornitore che come utente di
soluzioni IA. Per questo è prevista l'integrazione di un *framework* di
*governance* dell'IA all'esistente quadro di governance del dato e la
revisione di processi e prassi già esistenti per garantire la conformità
legale ed etica lungo tutto il ciclo di vita delle soluzioni IA.

L'**INPS** ha maturato una significativa esperienza in materia di
Intelligenza artificiale (IA) e IA generativa. Nel documento sono
riportati gli elementi fondamentali di alcuni dei principali progetti
ideati e implementati dall'INPS con l'obiettivo di potenziare i servizi
offerti all'utenza mediante l'impiego dell'intelligenza artificiale. I
progetti brevemente presentati riguardano:

-  La classificazione e lo smistamento automatico della Posta
   Elettronica Certificata (PEC)

-  La gestione delle richieste al *Customer Service*

-  L' "Assistente virtuale"

-  Iniziative di AI nell'ambito contenzioso e legale.

Anche **ISTAT** ha attivato diversi progetti per esplorare le
potenzialità dell'IA nell'ambito delle proprie attività istituzionali.
Da anni l'Ente utilizza tecniche di IA attraverso l'uso delle ontologie
per modellare i dati. Infatti, il linguaggio logico delle ontologie è in
grado di abilitare il "ragionamento automatico" (*reasoner*) per il
controllo della qualità dei dati, recuperando eventuali incoerenze sui
dati e fornendo nuove informazioni non direttamente ottenibili dalle
analisi dei dati stessi.

Recentemente, ISTAT sta esplorando una possibile soluzione attraverso
l'uso di algoritmi di AI generativa per produrre ontologie partendo da
una descrizione in linguaggio naturale del contesto semantico che si
vuole modellare. La necessaria interazione con gli specialisti consente
sia l'addestramento degli algoritmi che il miglioramento della qualità
della modellazione. Una possibile applicazione di tali tecniche
generative può essere utilizzata nell'ambito della gestione dei dati
delle pubbliche amministrazioni, per rendere i dati amministrativi
interoperabili attraverso le tecniche del *semantic web*, ottimizzando
l'impegno - di risorse con competenze specialistiche elevate.

Altri casi di studio, in corso di verifiche, riguardano la produzione
dei dati statistici, dalla loro raccolta alla diffusione.

5.4 - Quadro di sintesi - elementi chiave
-----------------------------------------

L'acquisizione di conoscenze e strumenti per l'analisi del rischio
nell'adozione di strumenti di Intelligenza artificiale (*AI*) è un
pilastro fondamentale per la Pubblica Amministrazione nel contesto
attuale, dove l'*AI Act* e altre normative emergenti pongono l'accento
sulla gestione dei rischi associati all'utilizzo dell'*AI*. Questo
impegno si concentra non solo sulla comprensione dei potenziali
pericoli, ma anche sulle modalità di interazione con questi sistemi
avanzati, riconoscendo che il carattere dei rischi può variare
significativamente a seconda delle specifiche applicazioni dell'*AI*.

L'analisi del rischio nell'*AI*, in linea con le direttive dell'*AI
Act*, prevede un'attenta valutazione che va oltre la semplice
identificazione delle criticità. Questo processo richiede una
comprensione approfondita delle diverse categorie di rischio stabilite
dalla normativa, che a loro volta implicano diversi livelli di controllo
e monitoraggio. L'essenza di questo approccio risiede nel riconoscere
che ogni applicazione dell'AI possiede caratteristiche uniche e, di
conseguenza, richiede una strategia su misura per gestire i rischi ad
essa associati.

Un elemento chiave per il raggiungimento di questo obiettivo è la
formazione e l'aggiornamento continuo delle competenze all'interno delle
amministrazioni pubbliche. Ciò implica non solo dotare i dipendenti
delle conoscenze tecniche necessarie per comprendere e gestire i rischi
dell'AI, ma anche sviluppare una cultura organizzativa che promuova la
consapevolezza e la responsabilità nei confronti di questi nuovi sistemi
tecnologici. In questo senso, l'analisi del rischio diventa un processo
dinamico, che evolve con il progresso tecnologico e l'accumulo di nuove
esperienze e conoscenze nel campo dell'AI.

5.5 - Risorse utili
-------------------

-  `Piano triennale per l'informatica nella Pubblica Amministrazione
   2024-2026 - Parte Terza, Strumento
   5 <https://docs.italia.it/italia/piano-triennale-ict/pianotriennale-ict-doc/it/2024-2026/strumenti/strumento-5_intelligenza-artificiale-nella-pubblica-amministrazione.html>`__
